# this can be any application server, not just unicorn
upstream app_server {
  # fail_timeout=0 means we always retry an upstream even if it failed
  # to return a good HTTP response (in case the unicorn master nukes a
  # single worker for timing out).

  # for UNIX domain socket setups:
  server unix:/tmp/logan-staging.sock fail_timeout=0;

  # for TCP setups, point these to your backend servers
  # server 192.168.0.8:8080 fail_timeout=0;
  # server 192.168.0.9:8080 fail_timeout=0;
}

# faster file serving at the expense of a small amount of ram
open_file_cache          max=5000  inactive=20s;
open_file_cache_valid    30s;
open_file_cache_min_uses 2;
open_file_cache_errors   on;

#redirect http -> https;
server {
  listen  80;
  server_name staging.patterns.brl.nyc;
  return  301 https://$server_name$request_uri;
}

server {

  listen 443 ssl http2 default deferred; # for Linux

  # If you have IPv6, you'll likely want to have two separate listeners.
  # One on IPv4 only (the default), and another on IPv6 only instead
  # of a single dual-stack listener.  A dual-stack listener will make
  # for ugly IPv4 addresses in $remote_addr (e.g ":ffff:10.0.0.1"
  # instead of just "10.0.0.1") and potentially trigger bugs in
  # some software.
  # listen [::]:80 ipv6only=on; # deferred or accept_filter recommended

  #ssl setup, using letsencrypt. see /etc/cron.weekly/letsencrypt.sh
  ssl_certificate /etc/letsencrypt/live/staging.patterns.brl.nyc/fullchain.pem;
  ssl_certificate_key /etc/letsencrypt/live/staging.patterns.brl.nyc/privkey.pem;
  ssl_session_cache shared:SSL:10m;
  ssl_session_timeout 10m;
  ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
  ssl_ciphers "ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS:!AES256";
  ssl_prefer_server_ciphers on;
  ssl_dhparam /etc/nginx/dhparam.pem;


  client_max_body_size 4G;
  server_name staging.patterns.brl.nyc;

  # ~2 seconds is often enough for most folks to parse HTML/CSS and
  # retrieve needed images/icons/frames, connections are cheap in
  # nginx so increasing this is generally safe...
  keepalive_timeout 5;

  # path for static files
  root /var/www/logan-staging/current/public;
  charset utf-8;

  # Prefer to serve static files directly from nginx to avoid unnecessary
  # data copies from the application server.
  #
  try_files $uri/index.html $uri.html $uri @app;

  # static asset browser based caching
  # cache.appcache, your document html and data
  # location ~* \.(?:manifest|appcache|html?|xml|json)$ {
  #   expires -1;
  #   # access_log logs/static.log; # I don't usually include a static log
  # }

  # # Feed
  # location ~* \.(?:rss|atom)$ {
  #   expires 1h;
  #   add_header Cache-Control "public";
  # }

  # # Media: images, icons, video, audio, HTC
  # location ~* \.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|ogg|ogv|webm|htc)$ {
  #   expires 1M;
  #   access_log off;
  #   add_header Cache-Control "public";
  # }

  # # CSS and Javascript
  # location ~* \.(?:css|js)$ {
  #   expires 1y;
  #   access_log off;
  #   add_header Cache-Control "public";
  # }

  location @app {
    # an HTTP header important enough to have its own Wikipedia entry:
    #   http://en.wikipedia.org/wiki/X-Forwarded-For
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

    # enable this if you forward HTTPS traffic to unicorn,
    # this helps Rack set the proper URL scheme for doing redirects:
    # proxy_set_header X-Forwarded-Proto $scheme;

    # pass the Host: header from the client right along so redirects
    # can be set properly within the Rack application
    proxy_set_header Host $http_host;

    # we don't want nginx trying to do something clever with
    # redirects, we set the Host: header above already.
    proxy_redirect off;

    # for great https
    proxy_set_header X-Forwarded-Proto $scheme;

    # send to our app
    proxy_pass http://app_server;

    # It's also safe to set if you're using only serving fast clients
    # with unicorn + nginx, but not slow clients.  You normally want
    # nginx to buffer responses to slow clients, even with Rails 3.1
    # streaming because otherwise a slow client can become a bottleneck
    # of unicorn.
    #
    # The Rack application may also set "X-Accel-Buffering (yes|no)"
    # in the response headers do disable/enable buffering on a
    # per-response basis.
    # proxy_buffering off;

  }

  # Rails error pages
  error_page 500 502 503 504 /500.html;
  location = /500.html {
    root /var/www/logan-staging/current/public;
  }
}