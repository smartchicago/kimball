# this can be any application server, not just unicorn
upstream app_server {
  # fail_timeout=0 means we always retry an upstream even if it failed
  # to return a good HTTP response (in case the unicorn master nukes a
  # single worker for timing out).

  # for UNIX domain socket setups:
  #server unix:/path/to/.unicorn.sock fail_timeout=0;

  # for TCP setups, point these to your backend servers
  server 127.0.0.1:8080 fail_timeout=0;
  # server 192.168.0.8:8080 fail_timeout=0;
  # server 192.168.0.9:8080 fail_timeout=0;
}

# create a 24MB cache directory in memory.
proxy_cache_path  /var/run/nginx levels=1:2 keys_zone=default:24m max_size=1000m inactive=30d;
proxy_temp_path   /var/run/nginx/tmp;
proxy_cache_key "$scheme$request_method$host$request_uri";

# faster file serving at the expense of a small amount of ram
open_file_cache          max=5000  inactive=20s;
open_file_cache_valid    30s;
open_file_cache_min_uses 2;
open_file_cache_errors   on;

server {

  listen 80 default deferred; # for Linux

  # If you have IPv6, you'll likely want to have two separate listeners.
  # One on IPv4 only (the default), and another on IPv6 only instead
  # of a single dual-stack listener.  A dual-stack listener will make
  # for ugly IPv4 addresses in $remote_addr (e.g ":ffff:10.0.0.1"
  # instead of just "10.0.0.1") and potentially trigger bugs in
  # some software.
  # listen [::]:80 ipv6only=on; # deferred or accept_filter recommended

  client_max_body_size 4G;
  server_name _;

  # ~2 seconds is often enough for most folks to parse HTML/CSS and
  # retrieve needed images/icons/frames, connections are cheap in
  # nginx so increasing this is generally safe...
  keepalive_timeout 5;

  # path for static files
  root /vagrant/public;
  charset utf-8;

  # Prefer to serve static files directly from nginx to avoid unnecessary
  # data copies from the application server.
  #
  # try_files directive appeared in in nginx 0.7.27 and has stabilized
  # over time.  Older versions of nginx (e.g. 0.6.x) requires
  # "if (!-f $request_filename)" which was less efficient:
  # http://bogomips.org/unicorn.git/tree/examples/nginx.conf?id=v3.3.1#n127
  try_files $uri/index.html $uri.html $uri @app;

  # static asset browser based caching
  # cache.appcache, your document html and data
  # location ~* \.(?:manifest|appcache|html?|xml|json)$ {
  #   expires -1;
  #   # access_log logs/static.log; # I don't usually include a static log
  # }

  # # Feed
  # location ~* \.(?:rss|atom)$ {
  #   expires 1h;
  #   add_header Cache-Control "public";
  # }

  # # Media: images, icons, video, audio, HTC
  # location ~* \.(?:jpg|jpeg|gif|png|ico|cur|gz|svg|svgz|mp4|ogg|ogv|webm|htc)$ {
  #   expires 1M;
  #   access_log off;
  #   add_header Cache-Control "public";
  # }

  # # CSS and Javascript
  # location ~* \.(?:css|js)$ {
  #   expires 1y;
  #   access_log off;
  #   add_header Cache-Control "public";
  # }

  location @app {
    # an HTTP header important enough to have its own Wikipedia entry:
    #   http://en.wikipedia.org/wiki/X-Forwarded-For
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

    # enable this if you forward HTTPS traffic to unicorn,
    # this helps Rack set the proper URL scheme for doing redirects:
    # proxy_set_header X-Forwarded-Proto $scheme;

    # pass the Host: header from the client right along so redirects
    # can be set properly within the Rack application
    proxy_set_header Host $http_host;

    # we don't want nginx trying to do something clever with
    # redirects, we set the Host: header above already.
    proxy_redirect off;

    # for great https
    proxy_set_header X-Forwarded-Proto $scheme;

    # send to our app
    proxy_pass http://app_server;

    # Reverse proxy cache
    proxy_cache default;
    proxy_cache_lock on;
    proxy_cache_use_stale updating;
    add_header X-Cache-Status $upstream_cache_status;

    # It's also safe to set if you're using only serving fast clients
    # with unicorn + nginx, but not slow clients.  You normally want
    # nginx to buffer responses to slow clients, even with Rails 3.1
    # streaming because otherwise a slow client can become a bottleneck
    # of unicorn.
    #
    # The Rack application may also set "X-Accel-Buffering (yes|no)"
    # in the response headers do disable/enable buffering on a
    # per-response basis.
    # proxy_buffering off;

  }

  # Rails error pages
  error_page 500 502 503 504 /500.html;
  location = /500.html {
    root /vagrant/public;
  }
}